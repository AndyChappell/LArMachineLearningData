{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the relevant scripts from LArMachineLearningData\n",
    "# Nice the process so it can run with lots of cores on low priority\n",
    "import os\n",
    "\n",
    "# Add path for LArMachineLearningData\n",
    "import sys\n",
    "pandoraMVADir = os.getcwd()\n",
    "sys.path.append(os.path.join(pandoraMVADir, 'scripts'))\n",
    "\n",
    "from PandoraBDT import *\n",
    "\n",
    "# Import relevant SKLearn stuff\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "# Set global params\n",
    "testTrainFraction = 0.5\n",
    "nCores = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dune_pfo_characterisation_metadata(bdt_sub_type):\n",
    "    \"\"\"\n",
    "        bdt_sub_type: 'Charge' or 'NoCharge'\n",
    "    \"\"\"\n",
    "    name = \"PFOCharBDT\"\n",
    "\n",
    "    features = ['Length',\n",
    "                'Straight Line Diff Mean',\n",
    "                'Max Fit Gap Length',\n",
    "                'Sliding Linear Fit RMS',\n",
    "                'Vertex Distance',\n",
    "                'PCA Secondary-Primary EigenValue Ratio',\n",
    "                'PCA Tertiary-Primary EigenValue Ratio',\n",
    "                'Hierarchy N Daughters',\n",
    "                'Hierarchy N Daughter Hits 3D',\n",
    "                'Hierarchy Daughter Parent Hit Ratio',\n",
    "                'Opening Angle Diff']\n",
    "    if bdt_sub_type.lower() == \"charge\":\n",
    "        features.append('Charge 1')\n",
    "        features.append('Charge 2')\n",
    "\n",
    "        # Set background and signal label names\n",
    "    params = {\n",
    "        'labelNames': ['True Shower','True Track'],\n",
    "        'signalDefs': [0, 1],\n",
    "        'signalCols': ['r', 'b'],\n",
    "        'nBins': 100,\n",
    "        'PlotStep': 1.0,\n",
    "        'OptimalBinCut': 50,\n",
    "        'OptimalScoreCut': 0.5,\n",
    "        'nTrees': 100,\n",
    "        'TreeDepth': 3,\n",
    "        'logY': False,\n",
    "        'figSize': (8, 6),\n",
    "        'titlesize': 18,\n",
    "        'labelsize': 14\n",
    "    }\n",
    "    return (name, features, params)\n",
    "\n",
    "def get_dune_vertex_selection_metadata(bdt_sub_type, mode):\n",
    "    \"\"\"\n",
    "        bdt_sub_type: 'Vertex' or 'Region'\n",
    "        mode: 'beam' or 'atmos'\n",
    "    \"\"\"\n",
    "    name = f\"DUNEFD_VertexSelection{bdt_sub_type.title()}\"\n",
    "    \n",
    "    # Event features\n",
    "    features = ['Showeryness',\n",
    "                'Energy',\n",
    "                'Area',\n",
    "                'Longitudinality',\n",
    "                'N Hits',\n",
    "                'N Clusters',\n",
    "                'N Candidates']\n",
    "    \n",
    "    # Vertex features\n",
    "    for candidate in [1, 2]:\n",
    "        if mode.lower() == \"beam\":\n",
    "            features.append(f'Beam Deweighting {candidate}')\n",
    "        features += [f'Energy Kick {candidate}',\n",
    "                     f'Global Asymmetry {candidate}',\n",
    "                     f'Local Asymmetry {candidate}',\n",
    "                     f'Shower Asymmetry {candidate}',\n",
    "                     f'dEdx Asymmetry {candidate}',\n",
    "                     f'Vertex Energy {candidate}']\n",
    "        if bdt_sub_type.lower() == \"vertex\":\n",
    "            features.append(f'rPhi {candidate}')\n",
    "    \n",
    "    # Shared features\n",
    "    features += ['Separation',\n",
    "                 'Axis Hits']\n",
    "    \n",
    "    params = {\n",
    "        'labelNames': ['Background','Vertex'],\n",
    "        'signalDefs': [0, 1],\n",
    "        'signalCols': ['r', 'b'],\n",
    "        'nBins': 100,\n",
    "        'PlotStep': 1.0,\n",
    "        'OptimalBinCut': 50,\n",
    "        'OptimalScoreCut': 0.5,\n",
    "        'nTrees': 100,\n",
    "        'TreeDepth': 1,\n",
    "        'logY': False,\n",
    "        'figsize': (8, 6),\n",
    "        'titlesize': 18,\n",
    "        'labelsize': 14\n",
    "    }\n",
    "    \n",
    "    return (name, features, params)\n",
    "    \n",
    "\n",
    "def get_bdt_metadata(experiment, bdt_type, bdt_sub_type=None, mode=None):\n",
    "    if experiment.lower() == \"dune\":\n",
    "        if bdt_type.lower() == \"pfocharacterisation\":\n",
    "            return get_dune_pfo_characterisation_metadata(bdt_sub_type)\n",
    "        elif bdt_type.lower() == \"vertexselection\":\n",
    "            return get_dune_vertex_selection_metadata(bdt_sub_type, mode)\n",
    "    else:\n",
    "        return (\"\", [], {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some analysis specific things\n",
    "bdt_type = \"atmos\"\n",
    "bdt_sub_type = \"Region\"\n",
    "trainingFile = os.path.join(os.getcwd(), f'training_files/VertexSelection{bdt_sub_type}.txt')\n",
    "\n",
    "BDTName, featureNames, params = get_bdt_metadata(\"DUNE\", \"VertexSelection\", f\"{bdt_sub_type}\", f\"{bdt_type}\")\n",
    "\n",
    "# Create the base BDT to vary the params from and compare to\n",
    "baseBDT = AdaBoostClassifier(DecisionTreeClassifier(max_depth=params['TreeDepth']),algorithm='SAMME', \n",
    "                         random_state=42, n_estimators=params['nTrees'])\n",
    "\n",
    "# Split the data into many subsets to grid search over (Set seed for reproducibility)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data, nFeatures, nExamples = LoadData(trainingFile, ',')\n",
    "featuresOrg, labelsOrg = SplitTrainingSet(data, nFeatures)\n",
    "features, labels = Randomize(featuresOrg, labelsOrg, True)\n",
    "\n",
    "# Split into train and test samples\n",
    "xTrain, yTrain, xTest, yTest = Sample(features, labels, testTrainFraction)\n",
    "\n",
    "# Split into signal and background based on the true labels\n",
    "signalFeatures = features[labels==1]\n",
    "backgroundFeatures = features[labels==0]\n",
    "\n",
    "# Check the features array is the same size as the feature names array\n",
    "print (len(featureNames))\n",
    "print (np.shape(features))\n",
    "print('Total: '+str(len(features))+', signal: '+\n",
    "      str(len(signalFeatures))+' and background: '+\n",
    "      str(len(backgroundFeatures)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the Pandas dataframe\n",
    "# First crete a dictionary\n",
    "allDict = {featureNames[i]: features[:, i] for i in range(nFeatures)}\n",
    "allDict.update({'Labels': labels})\n",
    "\n",
    "# Create the Pandas dataframe, create seperate df for signal/background\n",
    "df = pd.DataFrame(data=allDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plots drawing the variables for signal/background\n",
    "DrawVariablesDF(df, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make correlation matricies\n",
    "dfSig = df[df['Labels']==params['signalDefs'][0]].drop('Labels', axis=1)\n",
    "dfBck = df[df['Labels']==params['signalDefs'][1]].drop('Labels', axis=1)\n",
    "\n",
    "CorrelationDF(dfSig, params['labelNames'][0] + ' Correlation Matrix', params)\n",
    "CorrelationDF(dfBck, params['labelNames'][1] + ' Correlation Matrix', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to make a plot comparing two variables;\n",
    "xMetric = 'Showeryness'\n",
    "yMetric = 'Energy Kick 1'\n",
    "\n",
    "sns.set(font_scale = 1)\n",
    "sns.jointplot(data=df, x=xMetric, y=yMetric, hue='Labels',\n",
    "              xlim=(np.quantile(df[xMetric], 0.02), np.quantile(df[xMetric], 0.98)), \n",
    "              ylim=(np.quantile(df[yMetric], 0.02), np.quantile(df[yMetric], 0.98)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting all combos, not very useful when we have too many variables\n",
    "#sns.pairplot(df, hue='Labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optionally drop features from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_indices = [ featureNames.index(val) for val in ['Energy', 'N Hits', 'N Candidates'] ]\n",
    "featureNames = np.delete(featureNames, drop_indices, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data, nFeatures, nExamples = LoadData(trainingFile, ',')\n",
    "featuresOrg, labelsOrg = SplitTrainingSet(data, nFeatures, drop_indices)\n",
    "nFeatures = featuresOrg.shape[1]\n",
    "features, labels = Randomize(featuresOrg, labelsOrg, True)\n",
    "\n",
    "# Split into train and test samples\n",
    "xTrain, yTrain, xTest, yTest = Sample(features, labels, testTrainFraction)\n",
    "\n",
    "# Split into signal and background based on the true labels\n",
    "signalFeatures = features[labels==1]\n",
    "backgroundFeatures = features[labels==0]\n",
    "\n",
    "# Check the features array is the same size as the feature names array\n",
    "print (len(featureNames))\n",
    "print (np.shape(features))\n",
    "print('Total: '+str(len(features))+', signal: '+\n",
    "      str(len(signalFeatures))+' and background: '+\n",
    "      str(len(backgroundFeatures)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search BDT hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "depthArray = [1, 2, 3]\n",
    "estimatorsArray = [50, 100, 200, 400]\n",
    "bdtArray = np.empty((len(depthArray), len(estimatorsArray)), dtype='object')\n",
    "for i, depth in enumerate(depthArray):\n",
    "    baseTree = DecisionTreeClassifier(max_depth=depth)\n",
    "    for j, estimators in enumerate(estimatorsArray):\n",
    "        bdtArray[i, j] = AdaBoostClassifier(baseTree, algorithm='SAMME', random_state=42, n_estimators=estimators)\n",
    "        bdtArray[i, j].fit(xTrain, yTrain)\n",
    "        PlotBdtKSScores(bdtArray[i, j], xTest, yTest, xTrain, yTrain, 'Vertex Region', params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseBDT = bdtArray[0][0]\n",
    "bestBDT = bdtArray[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "metrics.plot_roc_curve(bestBDT, xTest, yTest, ax=ax, name=\"Best\")\n",
    "metrics.plot_roc_curve(baseBDT, xTest, yTest, ax=ax, name=\"Base\")\n",
    "\n",
    "plt.title(\"ROC Curves\")\n",
    "ax.invert_xaxis()\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "plt.savefig('ROC.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matricies\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "metrics.plot_confusion_matrix(bestBDT, xTest, yTest, display_labels=params['labelNames'],\n",
    "                             ax=ax, normalize='true')\n",
    "ax.invert_xaxis()\n",
    "#ax.invert_zaxis()\n",
    "plt.title(\"Confusion matrix (True Normalised)\")\n",
    "plt.show()\n",
    "plt.savefig('Confusion.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print more detailed performance info\n",
    "bdtPredicted = baseBDT.predict(xTest)\n",
    "gridPredicted = bestBDT.predict(xTest)\n",
    "\n",
    "print (\"Background (0): \", params['labelNames'][0])\n",
    "print (\"Signal (1): \", params['labelNames'][1])\n",
    "print (\"BDT:\\n\", metrics.classification_report(yTest, bdtPredicted))\n",
    "print (\"Grid:\\n\", metrics.classification_report(yTest, gridPredicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseBDT = bestBDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search performance over training sample size\n",
    "train_sizes_array = np.linspace(0.5, 1, 6)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(baseBDT, features,\n",
    "    labels, train_sizes=train_sizes_array[1:], n_jobs=nCores, verbose=9, cv=cv)\n",
    "\n",
    "mean_train_scores = np.mean(train_scores, axis=1)\n",
    "mean_test_scores = np.mean(test_scores, axis=1)\n",
    "\n",
    "std_train_scores = np.std(train_scores, axis=1)\n",
    "std_test_scores = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training progression\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "plt.title(\"Training Progression\")\n",
    "plt.xlabel(\"Number of Training Examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "\n",
    "plt.plot(train_sizes, mean_train_scores, label='Train Score', color='b')\n",
    "plt.fill_between(train_sizes, mean_train_scores - std_train_scores,\n",
    "                         mean_train_scores + std_train_scores, alpha=0.1,\n",
    "                         color=\"b\")\n",
    "\n",
    "plt.plot(train_sizes, mean_test_scores, label='Test Score', color='r')\n",
    "plt.fill_between(train_sizes, mean_test_scores - std_test_scores,\n",
    "                         mean_test_scores + std_test_scores, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "#plt.plot(train_sizes, std_test_scores, label='Test Score Std.', color='k')\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.savefig('TrainingSize.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search over a metric\n",
    "cppalplhaArray = np.linspace(0, 0.001, 6)\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    baseBDT, features, labels, param_name='base_estimator__ccp_alpha',\n",
    "    param_range=cppalplhaArray, n_jobs=nCores, verbose=9, cv=cv)\n",
    "\n",
    "mean_train_scores = np.mean(train_scores, axis=1)\n",
    "mean_test_scores = np.mean(test_scores, axis=1)\n",
    "\n",
    "std_train_scores = np.std(train_scores, axis=1)\n",
    "std_test_scores = np.std(test_scores, axis=1)\n",
    "\n",
    "print (\"Means: \"+str(mean_test_scores)+\" and std. \"\n",
    "       +str(std_test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot grid search\n",
    "plt.plot(cppalplhaArray, mean_train_scores, label='Train Score', color='b')\n",
    "plt.fill_between(cppalplhaArray, mean_train_scores - std_train_scores,\n",
    "                         mean_train_scores + std_train_scores, alpha=0.1,\n",
    "                         color=\"b\")\n",
    "plt.plot(cppalplhaArray, mean_test_scores, label='Test Score', color='r')\n",
    "plt.fill_between(cppalplhaArray, mean_test_scores - std_test_scores,\n",
    "                         mean_test_scores + std_test_scores, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "plt.grid()\n",
    "#plt.xscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search over a metric\n",
    "learningRateArray = np.linspace(0.1,1.5, 8)\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    baseBDT, features, labels, param_name='learning_rate',\n",
    "    param_range=learningRateArray, n_jobs=nCores, verbose=9, cv=cv)\n",
    "\n",
    "mean_train_scores = np.mean(train_scores, axis=1)\n",
    "mean_test_scores = np.mean(test_scores, axis=1)\n",
    "\n",
    "std_train_scores = np.std(train_scores, axis=1)\n",
    "std_test_scores = np.std(test_scores, axis=1)\n",
    "\n",
    "print (\"Means: \"+str(mean_test_scores)+\" and std. \"\n",
    "       +str(std_test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot grid search\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "plt.plot(learningRateArray, mean_train_scores, label='Train Score', color='b')\n",
    "plt.fill_between(learningRateArray, mean_train_scores - std_train_scores,\n",
    "                         mean_train_scores + std_train_scores, alpha=0.1,\n",
    "                         color=\"b\")\n",
    "plt.plot(learningRateArray, mean_test_scores, label='Test Score', color='r')\n",
    "plt.fill_between(learningRateArray, mean_test_scores - std_test_scores,\n",
    "                         mean_test_scores + std_test_scores, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "plt.grid()\n",
    "#plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.savefig('LearningRate.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseTree = DecisionTreeClassifier(max_depth=bestBDT.estimators_[0].max_depth)\n",
    "baseBDT = AdaBoostClassifier(baseTree, algorithm='SAMME', random_state=42, n_estimators=bestBDT.n_estimators,\n",
    "                             learning_rate=1.3)\n",
    "baseBDT.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot importance of features\n",
    "importanceDF = pd.DataFrame({'Features': featureNames, 'Importance Score':baseBDT.feature_importances_})\n",
    "print (importanceDF.sort_values(by=['Importance Score']))\n",
    "ax = importanceDF.sort_values(by=['Importance Score'])\\\n",
    "    .plot(kind='barh', x='Features', y='Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all tunable params\n",
    "baseBDT.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PandoraBDT\n",
    "from importlib import reload\n",
    "\n",
    "reload (PandoraBDT)\n",
    "from PandoraBDT import *\n",
    "\n",
    "print (np.shape(xTest))\n",
    "print (np.shape(yTest))\n",
    "print (np.shape(xTrain))\n",
    "print (np.shape(yTrain))\n",
    "\n",
    "PlotBdtKSScores(baseBDT, xTest, yTest, xTrain, yTrain, 'Vertex Region', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "metrics.plot_roc_curve(baseBDT, xTest, yTest, ax=ax, name=\"Best\")\n",
    "metrics.plot_roc_curve(bdtArray[0][0], xTest, yTest, ax=ax, name=\"Base\")\n",
    "\n",
    "plt.title(\"ROC Curves\")\n",
    "ax.invert_xaxis()\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "plt.savefig('ROCFinal.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matricies\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "metrics.plot_confusion_matrix(baseBDT, xTest, yTest, display_labels=params['labelNames'],\n",
    "                             ax=ax, normalize='true')\n",
    "ax.invert_xaxis()\n",
    "#ax.invert_zaxis()\n",
    "plt.title(\"Confusion matrix (True Normalised)\")\n",
    "plt.show()\n",
    "plt.savefig('ConfusionFinal.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WriteXmlFile(BDTName+\".xml\", baseBDT, BDTName)\n",
    "SerializeToPkl(BDTName+\".pkl\", baseBDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
