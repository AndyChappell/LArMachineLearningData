{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb054b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Setup!\n",
    "isWeighted = False\n",
    "nTrees     = 1000\n",
    "maxDepth   = 3\n",
    "\n",
    "plotVariables = True\n",
    "\n",
    "version  = \"Final\"\n",
    "\n",
    "version += (\"_\" + str(nTrees) + \"_\" + str(maxDepth))\n",
    "\n",
    "print(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208b375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the relevant scripts from LArMachineLearningData\n",
    "# Nice the process so it can run with lots of cores on low priority\n",
    "import os\n",
    "\n",
    "# Add path for LArMachineLearningData\n",
    "import sys\n",
    "pandoraMVADir = \"\"\n",
    "#dataDir       = \"../\"\n",
    "dataDir       = \"./\"\n",
    "\n",
    "#sys.path.append(pandoraMVADir + 'LArMachineLearningData/scripts')\n",
    "sys.path.append(pandoraMVADir + '.')\n",
    "\n",
    "# Import pandora libraries\n",
    "from importlib import reload\n",
    "from PandoraBDT import *\n",
    "\n",
    "# Import concatenation tool\n",
    "from itertools import chain\n",
    "\n",
    "# Import relevant SKLearn libraries\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "# Set global params\n",
    "testTrainFraction = 0.5\n",
    "nCores = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b5fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and Name\n",
    "trainingFile = dataDir + 'training_output_hierarchy.txt'\n",
    "#trainingFile = dataDir + 'training_outputnoChargeInfo.txt'\n",
    "BDTName = \"PfoCharacterisation\"\n",
    "\n",
    "# Directories\n",
    "plotsDir = pandoraMVADir + 'bdt/plots/' + BDTName + '/' + version + '/'\n",
    "saveDir  = pandoraMVADir + 'bdt/trained/' + BDTName + '/' + version + '/'\n",
    "print(plotsDir)\n",
    "print(saveDir)\n",
    "\n",
    "if not os.path.exists(plotsDir):\n",
    "    os.makedirs(plotsDir)\n",
    "    \n",
    "if not os.path.exists(saveDir):\n",
    "    os.makedirs(saveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41d2136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set background and signal label names\n",
    "params = {\n",
    "    'labelNames': ['Shower','Track'],\n",
    "    'signalDefs': [0, 1],\n",
    "    'signalCols': ['r', 'b']\n",
    "}\n",
    "\n",
    "# Create the base BDT to vary the params from and compare to\n",
    "baseBDT = AdaBoostClassifier(DecisionTreeClassifier(max_depth=maxDepth),algorithm='SAMME', \n",
    "                             random_state=42, n_estimators=nTrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83ca5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data, nFeatures, nExamples = LoadData(trainingFile, ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f57a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels           = SplitTrainingSet(data, nFeatures)\n",
    "\n",
    "# Split into train and test samples\n",
    "xTrain, yTrain, xTest, yTest = Sample(features, labels, testTrainFraction)\n",
    "\n",
    "# Split into signal and background based on the true labels\n",
    "signalFeatures = features[labels==1]\n",
    "backgroundFeatures = features[labels==0]\n",
    "\n",
    "# Check the features array is the same size as the feature names array\n",
    "print (len(features[0]))\n",
    "print (np.shape(features))\n",
    "print('Total: '+str(len(features))+', signal: '+\n",
    "      str(len(signalFeatures))+' and background: '+\n",
    "      str(len(backgroundFeatures)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74b6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the Pandas dataframe\n",
    "# First create a dictionary\n",
    "allDict = {i: features[:, i] for i in range(nFeatures)}\n",
    "allDict.update({'Labels': labels})\n",
    "\n",
    "# Create the Pandas dataframe, create seperate df for signal/background\n",
    "df = pd.DataFrame(data=allDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27cb7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3faa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawVariablesDF(df, params, topdir, save=True):\n",
    "    for column in df:\n",
    "        if column == 'Labels':\n",
    "            continue    \n",
    "        fig, ax = plt.subplots()\n",
    "        df.pivot(columns='Labels')[column].plot.hist(bins=50, alpha=0.5, color=params['signalCols'], edgecolor='k', density=True, ax=ax)\n",
    "        ax.legend(params['labelNames']);\n",
    "        ax.set_xlabel(column)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if save:\n",
    "            plt.savefig(topdir + 'Feature_' + str(column) + '.png')\n",
    "            plt.savefig(topdir + 'Feature_' + str(column) + '.pdf')\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be1e80b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make plots drawing the variables for signal/background\n",
    "if plotVariables : DrawVariablesDF(df, params, plotsDir, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4a4979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Correlation(df, label, topdir, save=False):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.title(label)\n",
    "\n",
    "    ax = sns.heatmap(df.corr(), cmap='coolwarm', vmax=1.0, vmin=-1.0,\n",
    "                     annot=True, square=True, fmt='.2g')\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(topdir + '/' + label.replace(\" \", \"_\") + \".png\", bbox_inches='tight')\n",
    "        plt.savefig(topdir + '/' + label.replace(\" \", \"_\") + \".pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4f818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make correlation matricies\n",
    "if plotVariables :\n",
    "    Correlation(df[df['Labels']==params['signalDefs'][0]], params['labelNames'][0] + ' Correlation Matrix',plotsDir, save = True)\n",
    "    Correlation(df[df['Labels']==params['signalDefs'][1]], params['labelNames'][1] + ' Correlation Matrix',plotsDir, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be388348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference BDT with controlled hyperparams\n",
    "baseBDT.fit(xTrain,yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a01c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots()\n",
    "metrics.plot_roc_curve(baseBDT, xTest, yTest, ax=ax)\n",
    "\n",
    "plt.title(\"ROC Curves\")\n",
    "ax.invert_xaxis()\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "plt.savefig(plotsDir + '/' + \"roc.png\", bbox_inches='tight')\n",
    "plt.savefig(plotsDir + '/' + \"roc.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3adaeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matricies\n",
    "fig, ax = plt.subplots()\n",
    "metrics.plot_confusion_matrix(baseBDT, xTest, yTest, display_labels=params['labelNames'],\n",
    "                             ax=ax, normalize='true')\n",
    "ax.invert_xaxis()\n",
    "plt.title(\"Confusion matrix (True Normalised)\")\n",
    "\n",
    "plt.savefig(plotsDir + '/' + \"confusion_matrix.png\", bbox_inches='tight')\n",
    "plt.savefig(plotsDir + '/' + \"confusion_matrix.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a58ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print more detailed performance info\n",
    "bdtPredicted = baseBDT.predict(xTest)\n",
    "\n",
    "print (\"Background (0): \", params['labelNames'][0])\n",
    "print (\"Signal (1): \", params['labelNames'][1])\n",
    "print (\"BDT:\\n\", metrics.classification_report(yTest, bdtPredicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092027de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot importance of features\n",
    "importanceDF = pd.DataFrame({'Features': range(len(features[0])), 'Importance Score':baseBDT.feature_importances_})\n",
    "print (importanceDF.sort_values(by=['Importance Score']))\n",
    "ax = importanceDF.sort_values(by=['Importance Score'])\\\n",
    "    .plot(kind='barh', x='Features', y='Importance Score')\n",
    "\n",
    "plt.savefig(plotsDir + '/' + \"feature_importance.png\", bbox_inches='tight')\n",
    "\n",
    "plt.savefig(plotsDir + '/' + \"feature_importance.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c2b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sci\n",
    "\n",
    "def PlotBdtScores2(bdtModel, X_test, Y_test, X_train, Y_train, title, parameters, topDir, save=False):\n",
    "    # Testing BDT Using Remainder of Training Sample\n",
    "    test_results = bdtModel.decision_function(X_test)\n",
    "    train_results = bdtModel.decision_function(X_train)\n",
    "\n",
    "    test_results_signal = test_results[Y_test == 1]\n",
    "    train_results_signal = train_results[Y_train == 1]\n",
    "    test_results_background = test_results[Y_test == 0]\n",
    "    train_results_background = train_results[Y_train == 0]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.set_title('Overtraining Test: ' + title)\n",
    "\n",
    "    sigEff = 0\n",
    "    bkgRej = 0\n",
    "\n",
    "    for i, n, g in zip(parameters['SignalDefinition'], parameters['ClassNames'], parameters['PlotColors']):\n",
    "        entries, bins, patches = ax.hist(train_results[Y_train == i],\n",
    "                                         bins=parameters['nBins'],\n",
    "                                         range=(-1, 1),\n",
    "                                         facecolor=g,\n",
    "                                         label='%s' % n,\n",
    "                                         alpha=.5,\n",
    "                                         density=True,\n",
    "                                         edgecolor='k')\n",
    "\n",
    "        counts, bin_edges = np.histogram(test_results[Y_test == i],\n",
    "                                         range=(-1, 1), bins=parameters['nBins'], density=True)\n",
    "\n",
    "        bin_centres = (bin_edges[:-1] + bin_edges[1:])/2.\n",
    "        ax.errorbar(bin_centres, counts, fmt='o', color=g)\n",
    "\n",
    "        if i == 1:\n",
    "            nEntries = sum(counts)\n",
    "            nEntriesPassing = sum(counts[parameters['OptimalBinCut']:])\n",
    "            sigEff = nEntriesPassing/nEntries\n",
    "        elif i == 0:\n",
    "            nEntries = sum(counts)\n",
    "            nEntriesFailing = sum(counts[:parameters['OptimalBinCut']])\n",
    "            bkgRej = nEntriesFailing/nEntries\n",
    "\n",
    "    signalKSTest, ksSig = sci.ks_2samp(\n",
    "        test_results_signal, train_results_signal)\n",
    "    backgroundKSTest, ksBck = sci.ks_2samp(\n",
    "        test_results_background, train_results_background)\n",
    "\n",
    "    score = bdtModel.score(X_test,Y_test)\n",
    "\n",
    "    plt.text(0.88, 0.5, \"Sig Eff: {:.2%}\\nBkg Rej: {:.2%}\\nScore Cut: {:.2}\\n\\nSig KS: {:.2}\\nBack KS: {:.2}\\nSig P: {:.2}\\nBck P: {:.2}\\n\\nScore: {:.4} \"\n",
    "             .format(sigEff, bkgRej, parameters['OptimalScoreCut'], signalKSTest, backgroundKSTest, ksSig, ksBck, score),\n",
    "             horizontalalignment='center',\n",
    "             verticalalignment='center',\n",
    "             transform=ax.transAxes)\n",
    "\n",
    "    x1, x2, y1, y2 = plt.axis()\n",
    "    plt.axis((x1, x2, y1, y2 * 1.1))\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Samples')\n",
    "    plt.xlabel('Score')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(topDir + '/' + title.replace(\" \", \"_\") + '.pdf')\n",
    "        plt.savefig(topDir + '/' + title.replace(\" \", \"_\") + '.png')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    print(\"KS Signal:     \"+str(signalKSTest)+\" with P value: \"+str(ksSig))\n",
    "    print(\"KS BackGround: \"+str(backgroundKSTest)+\" with P value: \"+str(ksBck))\n",
    "\n",
    "    txt = str(title.replace(\"Vertex Vertex \",\"\").replace(\"Vertex Region \",\"\").replace(\"_\",\"\").replace(\" \",\"\")) + ' & {score:.4} & {signalKSTest:.2} (p={ksSig:.2}) & {backgroundKSTest:.2} (p={ksBck:.2})'\n",
    "    print(txt.format(score=score*100, signalKSTest=signalKSTest, ksSig=ksSig, backgroundKSTest=backgroundKSTest, ksBck=ksBck))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d20e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import PandoraBDT\n",
    "reload (PandoraBDT)\n",
    "from PandoraBDT import *\n",
    "\n",
    "parameters = {\n",
    "  'ClassNames': ['True Vertex', 'Incorrect Vertex'],\n",
    "  'SignalDefinition': [1, 0],\n",
    "  'PlotColors': ['b', 'r'],\n",
    "  'nBins': 100,\n",
    "  'PlotStep': 1.0,\n",
    "  'OptimalBinCut': 0,\n",
    "  'OptimalScoreCut': 0.0,\n",
    "  'nTrees': 100,\n",
    "  'TreeDepth': 3\n",
    "}\n",
    "\n",
    "FindOptimalSignificanceCut(baseBDT, xTest, yTest, parameters)\n",
    "PlotBdtScores2(baseBDT, xTest, yTest, xTrain, yTrain, 'Vertex Region ' + version, parameters, plotsDir, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2510e558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
