{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vertex performance assessment\n",
    "\n",
    "This notebook processes the output of the <code>VertexMonitoringAlgorithm</code> to allow comparison of the vertexing performance of different vertexing implementations.\n",
    "\n",
    "The setup for this assessment allows for the comparison of either two or three samples (this can be helpful for looking at the performance of individual passes of the vertexing network), but it should be fairly clear how to adapt the functions to  present a single case without a reference.\n",
    "\n",
    "The original implementation of this notebook assumed a comparison between the Pandora vertexing BDT and the newer Pandora deep-learning approach, and as such, the plot labels typically refer to 'Pandora' as the referenece BDT version, and 'Pandora DL' as the deep-learning version, with pass 1 and pass 2 suffixes as appropriate.\n",
    "\n",
    "Hopefully the individual function names are fairly self-explanatory given that context. The cells up until the 'Two sample comparisons' can be run in order, possibly after updating labels to suit the current use case.\n",
    "\n",
    "After this, you can run either the two or three sample sections after updating the input file locations and the output filename prefixes as appropriate.\n",
    "\n",
    "The statistics of interest in these sections are the 'drXY' values, which indicate the maximum distance between the reconstructed and true vertice at which XY% of all event are covered, and then the '% < Xcm' value, which indicate what fraction of events have vertices within a given distance of the true vertex. Finally, these sections produce plots showing the distributions of dr, dx, dy and dz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filename, treename):\n",
    "    file = uproot.open(filename)\n",
    "    tree = file[treename]\n",
    "    successes = tree['success'].array(library=\"np\")\n",
    "    true_nu_energy = tree['trueNuEnergy'].array(library=\"np\")\n",
    "    drs = tree['dr'].array(library=\"np\")\n",
    "    dxs = tree['dx'].array(library=\"np\")\n",
    "    dys = tree['dy'].array(library=\"np\")\n",
    "    dzs = tree['dz'].array(library=\"np\")\n",
    "    passing_idx = np.where(successes == 1)\n",
    "    file.close()\n",
    "    return drs, dxs, dys, dzs, passing_idx, true_nu_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_plot(fig, filename, subdir=None):\n",
    "    if subdir is None:\n",
    "        subdir = \"\"\n",
    "    elif subdir.startswith(\"/\"):\n",
    "        subdir = subdir[1:]\n",
    "        \n",
    "    if not os.path.exists('images'):\n",
    "        os.mkdir('images')\n",
    "    for img_type in [ \"png\", \"svg\", \"eps\", \"pdf\" ]:\n",
    "        if not os.path.exists(f'images/{img_type}'):\n",
    "            os.mkdir(f'images/{img_type}')\n",
    "        if not os.path.exists(f'images/{img_type}/{subdir}'):\n",
    "            os.mkdir(f'images/{img_type}/{subdir}')\n",
    "        fig.savefig(f'images/{img_type}/{subdir}/{filename}.{img_type}', dpi=200, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsize=14\n",
    "titlesize=18\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tck\n",
    "\n",
    "def plot_dr(drs1, drs2, file_prefix):\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    \n",
    "    bins = np.logspace(-2, 7, 10, base=3)\n",
    "    weights1 = np.ones_like(drs1) / len(drs1)\n",
    "    ax.hist(drs1, bins=bins, weights=weights1, histtype='step', lw=2, label=\"Pandora Ref\")\n",
    "    weights2 = np.ones_like(drs2) / len(drs2)\n",
    "    ax.hist(drs2, bins=bins, weights=weights2, histtype='step', lw=2, label=\"Pandora New\")\n",
    "    \n",
    "    ax.set_title(\"3D vertex reconstruction\", fontsize=titlesize)\n",
    "    ax.tick_params(axis='x', labelsize=labelsize)\n",
    "    ax.tick_params(axis='y', labelsize=labelsize)\n",
    "    ax.set_xlabel(\"reco - true (cm)\", fontsize=titlesize)\n",
    "    ax.set_ylabel(\"f\", fontsize=titlesize)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xticks(bins)\n",
    "    ax.get_xaxis().set_major_formatter(tck.LogFormatter(base=3))\n",
    "    ax.legend(fontsize=titlesize)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    save_plot(fig, f'{file_prefix}')\n",
    "    \n",
    "    \n",
    "def plot_dr_zoom(drs1, drs2, file_prefix):\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    \n",
    "    bins = np.linspace(0, 10, 20)\n",
    "    weights1 = np.ones_like(drs1) / len(drs1)\n",
    "    ax.hist(drs1, bins=bins, weights=weights1, histtype='step', lw=2, label=\"Pandora Ref\")\n",
    "    weights2 = np.ones_like(drs2) / len(drs2)\n",
    "    ax.hist(drs2, bins=bins, weights=weights2, histtype='step', lw=2, label=\"Pandora New\")\n",
    "    \n",
    "    ax.set_title(\"3D vertex reconstruction\", fontsize=titlesize)\n",
    "    ax.tick_params(axis='x', labelsize=labelsize)\n",
    "    ax.tick_params(axis='y', labelsize=labelsize)\n",
    "    ax.set_xlabel(\"reco - true (cm)\", fontsize=titlesize)\n",
    "    ax.set_ylabel(\"f\", fontsize=titlesize)\n",
    "    ax.legend(fontsize=titlesize)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    save_plot(fig, f'{file_prefix}')\n",
    "\n",
    "\n",
    "def plot_dx(dxs1, dxs2, file_prefix, axis='x'):\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    \n",
    "    bins = np.linspace(-2.55, 2.55, 52)\n",
    "    weights1 = np.ones_like(dxs1) / len(dxs1)\n",
    "    ax.hist(dxs1, bins=bins, weights=weights1, histtype='step', lw=2, label=\"Pandora Ref\")\n",
    "    weights2 = np.ones_like(dxs2) / len(dxs2)\n",
    "    ax.hist(dxs2, bins=bins, weights=weights2, histtype='step', lw=2, label=\"Pandora New\")\n",
    "    \n",
    "    ax.set_title(f\"Vertex reconstruction (d{axis})\", fontsize=titlesize)\n",
    "    ax.tick_params(axis='x', labelsize=labelsize)\n",
    "    ax.tick_params(axis='y', labelsize=labelsize)\n",
    "    ax.set_xlabel(\"reco - true (cm)\", fontsize=titlesize)\n",
    "    ax.set_ylabel(\"f\", fontsize=titlesize)\n",
    "    ax.legend(fontsize=titlesize)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    save_plot(fig, f'{file_prefix}')\n",
    "\n",
    "\n",
    "def plot_energy(energy0, energy1, file_prefix):\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    \n",
    "    bins = np.logspace(-3, 7, 11, base=2)\n",
    "    ax.hist(energy0, bins=bins, histtype='step', lw=2, label='All events')\n",
    "    ax.hist(energy1, bins=bins, histtype='step', lw=2, label='Reconstructed events')\n",
    "    \n",
    "    ax.set_title(\"True neutrino energy\", fontsize=titlesize)\n",
    "    ax.tick_params(axis='x', labelsize=labelsize)\n",
    "    ax.tick_params(axis='y', labelsize=labelsize)\n",
    "    ax.set_xlabel(\"energy (GeV)\", fontsize=titlesize)\n",
    "    ax.set_ylabel(\"f\", fontsize=titlesize)\n",
    "    ax.legend(fontsize=titlesize)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xticks(bins)\n",
    "    ax.get_xaxis().set_major_formatter(tck.LogFormatter(base=2))\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    save_plot(fig, f'{file_prefix}')\n",
    "\n",
    "\n",
    "def plot_dr_vs_energy(energy, drs0):\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    \n",
    "    bins = np.logspace(-3, 7, 11, base=2)\n",
    "    print(bins)\n",
    "    indices_set = [ np.where((energy_1[passing_idx_1] >= bins[i]) & (energy_1[passing_idx_1] < bins[i + 1]))\n",
    "                   for i in range(len(bins) - 1) ]\n",
    "    drs_set = [ drs0[indices] for indices in indices_set ]\n",
    "    bins_dr = np.logspace(-3, 10, 14, base=2)\n",
    "    for i, drs in enumerate(drs_set):\n",
    "        weights = np.ones_like(drs) / len(drs)\n",
    "        ax.hist(drs, histtype='step', bins=bins_dr, weights=weights, lw=2, label=f\"{bins[i]} - {bins[i+1]} GeV\")\n",
    "    ax.set_title(\"dr vs true neutrino energy\", fontsize=titlesize)\n",
    "    ax.tick_params(axis='x', labelsize=labelsize)\n",
    "    ax.tick_params(axis='y', labelsize=labelsize)\n",
    "    ax.set_xlabel(\"dr\", fontsize=titlesize)\n",
    "    ax.set_ylabel(\"f\", fontsize=titlesize)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xticks(bins)\n",
    "    ax.get_xaxis().set_major_formatter(tck.LogFormatter(base=2))\n",
    "    ax.legend(fontsize=titlesize)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two sample comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drs_0, dxs_0, dys_0, dzs_0, passing_idx_0, energy_0 = load_file('vertices_atmos_bdt.root', 'vertices')\n",
    "drs_1, dxs_1, dys_1, dzs_1, passing_idx_1, energy_1 = load_file('vertices_atmos_dl.root', 'vertices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dxs_0[passing_idx_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dxs_1[passing_idx_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_dx(dxs_0[passing_idx_0], dxs_1[passing_idx_1], \"atmos_dxs\", axis='x')\n",
    "plot_dx(dys_0[passing_idx_0], dys_1[passing_idx_1], \"atmos_dys\", axis='y')\n",
    "plot_dx(dzs_0[passing_idx_0], dzs_1[passing_idx_1], \"atmos_dzs\", axis='z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dr(drs_0[passing_idx_0], drs_1[passing_idx_1], \"atmos_deltas\")\n",
    "plot_dr_zoom(drs_0[passing_idx_0], drs_1[passing_idx_1], \"atmos_deltas_zoom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'dr68: {np.percentile(drs_0[passing_idx_0], 68.2):.1f}')\n",
    "print(f'dr90: {np.percentile(drs_0[passing_idx_0], 90.0):.1f}')\n",
    "print(f'dr95: {np.percentile(drs_0[passing_idx_0], 95.45):.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'dr68: {np.percentile(drs_1[passing_idx_1], 68.2):.1f}')\n",
    "print(f'dr90: {np.percentile(drs_1[passing_idx_1], 90.0):.1f}')\n",
    "print(f'dr95: {np.percentile(drs_1[passing_idx_1], 95.45):.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_drs_0 = np.sort(drs_0[passing_idx_0])\n",
    "print(f\"% < 1cm: {100 * np.where(sorted_drs_0 < 1)[0][-1] / len(sorted_drs_0):.1f}\")\n",
    "print(f\"% < 2cm: {100 * np.where(sorted_drs_0 < 2)[0][-1] / len(sorted_drs_0):.1f}\")\n",
    "print(f\"% < 3cm: {100 * np.where(sorted_drs_0 < 3)[0][-1] / len(sorted_drs_0):.1f}\")\n",
    "print(f\"% < 5cm: {100 * np.where(sorted_drs_0 < 5)[0][-1] / len(sorted_drs_0):.1f}\")\n",
    "print(f\"% < 10cm: {100 * np.where(sorted_drs_0 < 10)[0][-1] / len(sorted_drs_0):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_drs_1 = np.sort(drs_1[passing_idx_1])\n",
    "print(f\"% < 1cm: {100 * np.where(sorted_drs_1 < 1)[0][-1] / len(sorted_drs_1):.1f}\")\n",
    "print(f\"% < 2cm: {100 * np.where(sorted_drs_1 < 2)[0][-1] / len(sorted_drs_1):.1f}\")\n",
    "print(f\"% < 3cm: {100 * np.where(sorted_drs_1 < 3)[0][-1] / len(sorted_drs_1):.1f}\")\n",
    "print(f\"% < 5cm: {100 * np.where(sorted_drs_1 < 5)[0][-1] / len(sorted_drs_1):.1f}\")\n",
    "print(f\"% < 10cm: {100 * np.where(sorted_drs_1 < 10)[0][-1] / len(sorted_drs_1):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
